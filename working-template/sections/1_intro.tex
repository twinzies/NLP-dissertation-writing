% TODO: P4
% Intro: Tell the full story of your paper at a high-level. I like the hourglass approach - start broad to appeal to the general audience, narrow into your specific approach, proposal and idea and finally end with a discussion on how the work fits into the grand scheme of things.
\section{Introduction}
\textcolor{black!30}{Throughout history, people have sought answers to personal questions, with such discussions shaped by prevailing social values, cultural norms, and ethical traditions. In contemporary contexts, large language models (LLMs) are assuming a new role, being increasingly employed not only as sources of information but also as interlocutors in affective conversations in the form of personal assistants.
Personal matters are inherently complex. As LLMs have achieved widespread global adoption, individuals consult models such as GPT and Claude for a diverse range of internal deliberations, spanning from concerns about professional trajectories to calling upon them in acute experiences such as managing an anxiety attack. Since before the recent advancements of tranformed based language models, people frequently turn to online platforms such as Reddit, partly for the advantages of anonymity and the reduced risk of social judgment from known peers. These same advantages are also shared by LLMs. However, the use of LLMs for personal queries introduces new challenges and risks, too. For example, LLMs may generate responses that are 'sycophantic', echoing the user's views rather than providing objective advice, or they may produce responses that are misaligned with social values.
Consequently, the growing reliance on LLMs for personal queries and the range of users they cater to underscores the necessity of examining responses produced by LLMs in personal queries through multiple analytical lenses consisting of different ethical values and psychosocial paradigms.}

\textcolor{black!30}{\lipsum[1-2]}


% 2. GPT suggestion: Narrowing to gaps -> then RQs
\subsection{Research Questions}\label{sec:RQs}
The context of queries can substantially shape LLM outputs, influencing not only personal questions posed by consumers but also analytical evaluations conducted by researchers, particularly within the LLM-as-a-judge paradigm. As research increasingly highlights patterns and concerns regarding the impacts of LLMs in personal queries and deliberation, there is a critical need for a framework that can analyze and compare responses across multiple value-based perspectives in contexts without clear normative answers, while also remaining extensible for researchers to incorporate additional paradigms as the field evolves. This motivates the following research questions: 

\medskip\textbf{RQ1:} How can a technical framework that systematically analyzes and compares responses from humans and LLMs across various psychosocial value paradigms be designed?  

\medskip\textbf{RQ2:} What inter- and intra-paradigm comparative insights can this framework yield across three different psychosocial frameworks (Goffman’s theory of face, Rogerian PCT and Rockeach Values) and how accurate are these when subjected to manual validation?

\medskip\textbf{RQ3:} What are the major observable differences between LLM and human responses to personal questions without clear normative ground-truth answers? 

Finally, we examine how the results may influence consumer behavior and broader societal outcomes, and we discuss potential control mechanisms at both the pre-inference and post-inference stages. Our work enables a systematic comparative analysis of potential benefits and risks, and presents a framework for leveraging the analytical insights in the intentional design of response LLM generation.


% One researcher's question was around the values in the OP's body of the post and the values in the people's response. Focus on some of the major influences in LLM contexts and how can they be used to influence the generation of responses with DeepReflect's analyses ? This can be gracefully woven into the discussion / future investigations section although a reference could be made here if necessary - demonstrating the systems' potential to address questions of researchers' investigative curiosity.

% 3. The contributions as "responses" to the RQs - but I'd like to pose that subtly.

% \textcolor{black!30}{Finally, we provide a demonstration of DeepReflect's capabilities in the generation of responses to personal queries - contrasting them with raw LLM responses.
% Several other research questions can be addressed with the design of the system - aiding the motivation of researchers and providing an improved design to users. While a discussion on these is provided in the Conclusion section (Section~\ref{sec:Conclusion}), the focus of this paper is on the three research questions above owing to constraints on time and other resources.}

% \subsection{Contributions}
% \textcolor{black!30}{Refer to the Sycophancy paper for how to write this.Reference discussion section in Conclusion (section 7) to broaden back out - how this work can fit in the grand scheme of LLM conversations and research.}

\subsection{Contributions}
The key contributions of this work are: (1) the design and implementation of an extensible framework for analyzing and comparing responses to personal queries across three distinct psychosocial paradigms; (2) a comparative analysis under Rogerian Person-Centered Therapy (PCT), Goffman’s theory of face and Rokeach’s Value Survey (RVS) framework, illustrating how the choice of the paradigm can shape the perception of a response; and (3) insights into the relative strengths and weaknesses of LLM versus human responses, and how these insights can inform the generation of customized responses to personal queries.

% \begin{itemize}
%     \item \textcolor{black!30}{\lipsum[8]}
%     \item \textcolor{black!30}{\lipsum[9]}
%     \item \textcolor{black!30}{\lipsum[10]}
% \end{itemize}